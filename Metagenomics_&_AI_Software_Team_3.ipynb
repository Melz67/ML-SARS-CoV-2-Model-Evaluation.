{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZyk1D9pNOZL",
        "outputId": "23b58fe8-35b6-4df8-f0c9-23e137eff502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2it66ZCWhJgt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ✅ تحميل البيانات الأصلية\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/train.csv\"\n",
        "df = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "# ✅ التأكد من وجود عمود Clade\n",
        "if 'Clade' not in df.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في البيانات!\")\n",
        "\n",
        "# ✅ تخزين بيانات التدريب والتحقق\n",
        "train_list = []\n",
        "val_list = []\n",
        "\n",
        "# ✅ تقسيم البيانات لكل Clade على حدة\n",
        "for clade, group in df.groupby('Clade'):\n",
        "    # 🔹 التأكد من وجود عدد كافٍ من العينات\n",
        "    if len(group) < 50000:\n",
        "        raise ValueError(f\"⚠️ عدد العينات في Clade {clade} أقل من 50,000!\")\n",
        "\n",
        "    # 🔹 أخذ 50,000 عينة لبيانات التدريب\n",
        "    train_clade = group.sample(n=50000, random_state=42)\n",
        "\n",
        "    # 🔹 باقي البيانات تذهب إلى مجموعة التحقق (Validation)\n",
        "    val_clade = group.drop(train_clade.index)\n",
        "\n",
        "    # ✅ إضافة البيانات إلى القوائم\n",
        "    train_list.append(train_clade)\n",
        "    val_list.append(val_clade)\n",
        "\n",
        "# ✅ تجميع البيانات المقسمة\n",
        "df_train = pd.concat(train_list).reset_index(drop=True)\n",
        "df_val = pd.concat(val_list).reset_index(drop=True)\n",
        "\n",
        "# ✅ التأكد من الأحجام النهائية\n",
        "if len(df_train) != 350000 or len(df_val) != 210000:\n",
        "    raise ValueError(\"❌ حجم بيانات التدريب أو التحقق غير صحيح!\")\n",
        "\n",
        "# ✅ حفظ البيانات الجديدة\n",
        "train_output = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "val_output = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "\n",
        "df_train.to_csv(train_output, index=False)\n",
        "df_val.to_csv(val_output, index=False)\n",
        "\n",
        "print(f\"✅ تم تقسيم البيانات وحفظها بنجاح:\")\n",
        "print(f\"🔹 بيانات التدريب: {train_output} ({len(df_train)} صف)\")\n",
        "print(f\"🔹 بيانات التحقق: {val_output} ({len(df_val)} صف)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXlHVYjuji8K",
        "outputId": "e0b73a42-d87b-4e58-d612-fffe1fe7be3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 التجربة رقم 1\n",
            "📌 التجربة 1 - F1 Score: 0.8336, AUC-ROC: 0.9747\n",
            "🔹 التجربة رقم 2\n",
            "📌 التجربة 2 - F1 Score: 0.8382, AUC-ROC: 0.9761\n",
            "🔹 التجربة رقم 3\n",
            "📌 التجربة 3 - F1 Score: 0.8341, AUC-ROC: 0.9751\n",
            "🔹 التجربة رقم 4\n",
            "📌 التجربة 4 - F1 Score: 0.8360, AUC-ROC: 0.9760\n",
            "✅ أفضل موديل كان في التجربة 2\n",
            "✅ F1 Score: 0.8382, AUC-ROC: 0.9761\n",
            "✅ تم حفظ الموديل في: /content/drive/My Drive/Colab Notebooks/best_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# ✅ تحميل بيانات التدريب الكاملة\n",
        "train_file = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "df_train = pd.read_csv(train_file, low_memory=False)\n",
        "\n",
        "# ✅ التأكد من وجود Clade\n",
        "if 'Clade' not in df_train.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في البيانات!\")\n",
        "\n",
        "# ✅ تحويل القيم النصية إلى أرقام باستخدام Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "df_train['Clade'] = encoder.fit_transform(df_train['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام\n",
        "for col in df_train.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # نتجنب تحويل العمود المستهدف مرتين\n",
        "        df_train[col] = LabelEncoder().fit_transform(df_train[col].astype(str))\n",
        "\n",
        "# ✅ المتغيرات لتخزين أفضل القيم\n",
        "best_model = None\n",
        "best_f1 = 0\n",
        "best_auc = 0\n",
        "best_iteration = None\n",
        "\n",
        "# ✅ تكرار العملية 4 مرات\n",
        "for i in range(1, 5):\n",
        "    print(f\"🔹 التجربة رقم {i}\")\n",
        "\n",
        "    # 🔹 اختيار 87,500 صف عشوائيًا\n",
        "    df_sample = df_train.sample(n=87500, random_state=i)\n",
        "\n",
        "    # 🔹 تقسيم البيانات 80% تدريب و 20% تحقق\n",
        "    X = df_sample.drop(columns=['Clade'])  # الميزات (features)\n",
        "    y = df_sample['Clade']  # التصنيفات (labels)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
        "\n",
        "    # ✅ تدريب الموديل باستخدام Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # ✅ التنبؤ على بيانات التحقق\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)  # ✅ الآن نأخذ كل الاحتمالات لكل الفئات\n",
        "\n",
        "    # ✅ حساب F1 Score و AUC-ROC\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # ✅ تمرير كل الاحتمالات لكل الفئات\n",
        "\n",
        "    print(f\"📌 التجربة {i} - F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # ✅ حفظ أفضل موديل\n",
        "    if auc > best_auc:\n",
        "        best_model = model\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_iteration = i\n",
        "\n",
        "# ✅ حفظ أفضل موديل\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model.pkl\"\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"✅ أفضل موديل كان في التجربة {best_iteration}\")\n",
        "print(f\"✅ F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc:.4f}\")\n",
        "print(f\"✅ تم حفظ الموديل في: {best_model_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd8CsQ9Zo6v7",
        "outputId": "2c88c492-8dea-4577-bf2f-9f3e2b396845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 نتائج التحقق على 210,000 صف:\n",
            "✅ F1 Score: 0.8057\n",
            "✅ AUC-ROC: 0.9687\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ✅ تحميل بيانات التحقق (Validation Set)\n",
        "val_file = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "df_val = pd.read_csv(val_file, low_memory=False)\n",
        "\n",
        "# ✅ تحميل أفضل موديل\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# ✅ التأكد من وجود Clade في البيانات\n",
        "if 'Clade' not in df_val.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في بيانات التحقق!\")\n",
        "\n",
        "# ✅ تحويل القيم النصية إلى أرقام باستخدام نفس LabelEncoder المستخدم في التدريب\n",
        "encoder = LabelEncoder()\n",
        "df_val['Clade'] = encoder.fit_transform(df_val['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام بنفس الطريقة المستخدمة أثناء التدريب\n",
        "for col in df_val.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # ✅ استثناء العمود المستهدف\n",
        "        df_val[col] = LabelEncoder().fit_transform(df_val[col].astype(str))\n",
        "\n",
        "# ✅ تقسيم البيانات إلى الميزات (X) والتصنيفات (y)\n",
        "X_val = df_val.drop(columns=['Clade'])\n",
        "y_val = df_val['Clade']\n",
        "\n",
        "# ✅ التنبؤ باستخدام أفضل موديل\n",
        "y_pred = best_model.predict(X_val)\n",
        "y_pred_proba = best_model.predict_proba(X_val)  # ✅ الآن نأخذ كل الاحتمالات لكل الفئات\n",
        "\n",
        "# ✅ حساب F1 Score و AUC-ROC\n",
        "f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # ✅ تمرير كل الاحتمالات لكل الفئات\n",
        "\n",
        "# ✅ طباعة النتائج\n",
        "print(\"📌 نتائج التحقق على 210,000 صف:\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(f\"✅ AUC-ROC: {auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjRAuQjftQS3",
        "outputId": "297d3247-3948-4d66-d7b5-d2168e947d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ تم حفظ التوقعات بنجاح في: /content/drive/My Drive/Colab Notebooks/test_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ✅ تحميل بيانات الاختبار (Test Set)\n",
        "test_file = \"/content/drive/My Drive/Colab Notebooks/test_features.csv\"\n",
        "df_test = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# ✅ الاحتفاظ بـ ID الأصلي\n",
        "if 'ID' in df_test.columns:\n",
        "    test_ids = df_test['ID']\n",
        "else:\n",
        "    raise ValueError(\"❌ ملف الاختبار لا يحتوي على عمود 'ID'!\")\n",
        "\n",
        "# ✅ تحميل أفضل موديل\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# ✅ التأكد من عدم وجود Clade لأنه مش موجود في بيانات الاختبار\n",
        "if 'Clade' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام بنفس الطريقة المستخدمة أثناء التدريب\n",
        "for col in df_test.select_dtypes(include=['object']).columns:\n",
        "    df_test[col] = LabelEncoder().fit_transform(df_test[col].astype(str))\n",
        "\n",
        "# ✅ تنفيذ التوقعات باستخدام الموديل\n",
        "y_pred = best_model.predict(df_test)\n",
        "\n",
        "# ✅ تحويل التوقعات إلى DataFrame مع الـ ID\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Predicted_Clade\": y_pred\n",
        "})\n",
        "\n",
        "# ✅ حفظ التوقعات في ملف CSV\n",
        "output_file = \"/content/drive/My Drive/Colab Notebooks/test_predictions.csv\"\n",
        "df_predictions.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✅ تم حفظ التوقعات بنجاح في: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSyT-_L77FsL",
        "outputId": "bb929423-962f-4ae1-857f-4e5f7752491b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 التجربة رقم 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:12:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 التجربة 1 - F1 Score: 0.8523, AUC-ROC: 0.9810\n",
            "🔹 التجربة رقم 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:14:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 التجربة 2 - F1 Score: 0.8531, AUC-ROC: 0.9808\n",
            "🔹 التجربة رقم 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:16:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 التجربة 3 - F1 Score: 0.8512, AUC-ROC: 0.9802\n",
            "🔹 التجربة رقم 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:17:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 التجربة 4 - F1 Score: 0.8541, AUC-ROC: 0.9812\n",
            "✅ أفضل موديل كان في التجربة 4\n",
            "✅ F1 Score: 0.8541, AUC-ROC: 0.9812\n",
            "✅ تم حفظ الموديل في: /content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\n",
            "✅ تم حفظ StandardScaler في: /content/drive/My Drive/Colab Notebooks/best_scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pickle\n",
        "\n",
        "# ✅ تحميل بيانات التدريب\n",
        "train_file = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "df_train = pd.read_csv(train_file, low_memory=False)\n",
        "\n",
        "# ✅ التأكد من وجود Clade\n",
        "if 'Clade' not in df_train.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في البيانات!\")\n",
        "\n",
        "# ✅ تحويل القيم النصية إلى أرقام باستخدام Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "df_train['Clade'] = encoder.fit_transform(df_train['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام\n",
        "for col in df_train.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':\n",
        "        df_train[col] = LabelEncoder().fit_transform(df_train[col].astype(str))\n",
        "\n",
        "# ✅ المتغيرات لحفظ أفضل موديل\n",
        "best_model = None\n",
        "best_f1 = 0\n",
        "best_auc = 0\n",
        "best_iteration = None\n",
        "\n",
        "# ✅ تجربة 4 مرات واختيار الأفضل\n",
        "for i in range(1, 5):\n",
        "    print(f\"🔹 التجربة رقم {i}\")\n",
        "\n",
        "    # 🔹 اختيار 87,500 صف عشوائيًا\n",
        "    df_sample = df_train.sample(n=87500, random_state=i)\n",
        "\n",
        "    # 🔹 تقسيم البيانات 80% تدريب و 20% تحقق\n",
        "    X = df_sample.drop(columns=['Clade'])\n",
        "    y = df_sample['Clade']\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
        "\n",
        "    # ✅ تطبيع البيانات\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "\n",
        "    # ✅ تدريب الموديل باستخدام XGBoost\n",
        "    model = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # ✅ التنبؤ على بيانات التحقق\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)\n",
        "\n",
        "    # ✅ حساب F1 Score و AUC-ROC\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")\n",
        "\n",
        "    print(f\"📌 التجربة {i} - F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # ✅ حفظ أفضل موديل\n",
        "    if auc > best_auc:\n",
        "        best_model = model\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_iteration = i\n",
        "        best_scaler = scaler\n",
        "\n",
        "# ✅ حفظ أفضل موديل و StandardScaler\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\"\n",
        "scaler_file = \"/content/drive/My Drive/Colab Notebooks/best_scaler.pkl\"\n",
        "\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "with open(scaler_file, 'wb') as f:\n",
        "    pickle.dump(best_scaler, f)\n",
        "\n",
        "print(f\"✅ أفضل موديل كان في التجربة {best_iteration}\")\n",
        "print(f\"✅ F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc:.4f}\")\n",
        "print(f\"✅ تم حفظ الموديل في: {best_model_file}\")\n",
        "print(f\"✅ تم حفظ StandardScaler في: {scaler_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvxv99dWvzNh",
        "outputId": "39cc3127-a0c4-4e2c-f3ee-757cc6a49ffb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8492558954724528,\n",
              " 0.9802253145655241,\n",
              " ID       0\n",
              " AA       0\n",
              " AC       0\n",
              " AG       0\n",
              " AT       0\n",
              "         ..\n",
              " TTA      0\n",
              " TTC      0\n",
              " TTG      0\n",
              " TTT      0\n",
              " Clade    0\n",
              " Length: 82, dtype: int64,\n",
              " Clade\n",
              " 5    34170\n",
              " 0    31274\n",
              " 3    30483\n",
              " 1    30130\n",
              " 4    28825\n",
              " 6    28618\n",
              " 2    26500\n",
              " Name: count, dtype: int64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ تحميل بيانات التحقق\n",
        "val_file = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "df_val = pd.read_csv(val_file, low_memory=False)\n",
        "\n",
        "# ✅ التحقق من القيم المفقودة\n",
        "missing_values = df_val.isnull().sum()\n",
        "\n",
        "# ✅ حذف أو استبدال القيم المفقودة\n",
        "df_val = df_val.dropna()\n",
        "\n",
        "# ✅ التأكد من وجود Clade في البيانات\n",
        "if 'Clade' not in df_val.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في بيانات التحقق!\")\n",
        "\n",
        "# ✅ تحويل القيم النصية إلى أرقام باستخدام نفس LabelEncoder المستخدم في التدريب\n",
        "encoder = LabelEncoder()\n",
        "df_val['Clade'] = encoder.fit_transform(df_val['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام بنفس الطريقة المستخدمة أثناء التدريب\n",
        "for col in df_val.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':\n",
        "        df_val[col] = LabelEncoder().fit_transform(df_val[col].astype(str))\n",
        "\n",
        "# ✅ تقسيم البيانات إلى الميزات (X) والتصنيفات (y)\n",
        "X_val = df_val.drop(columns=['Clade'])\n",
        "y_val = df_val['Clade']\n",
        "\n",
        "# ✅ تحليل توازن الفئات\n",
        "class_distribution = y_val.value_counts()\n",
        "\n",
        "# ✅ موازنة البيانات باستخدام SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_val_balanced, y_val_balanced = smote.fit_resample(X_val, y_val)\n",
        "\n",
        "# ✅ تطبيع البيانات\n",
        "scaler = StandardScaler()\n",
        "X_val_scaled = scaler.fit_transform(X_val_balanced)\n",
        "\n",
        "# ✅ تحميل أفضل موديل XGBoost\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# ✅ التنبؤ باستخدام أفضل موديل XGBoost\n",
        "y_pred = best_model.predict(X_val_scaled)\n",
        "y_pred_proba = best_model.predict_proba(X_val_scaled)\n",
        "\n",
        "# ✅ حساب F1 Score و AUC-ROC\n",
        "f1 = f1_score(y_val_balanced, y_pred, average='weighted')\n",
        "auc = roc_auc_score(y_val_balanced, y_pred_proba, multi_class=\"ovr\")\n",
        "\n",
        "# ✅ تحليل أهمية الميزات\n",
        "feature_importance = best_model.feature_importances_\n",
        "top_features_idx = np.argsort(feature_importance)[-10:]\n",
        "top_features = X_val.columns[top_features_idx]\n",
        "top_importances = feature_importance[top_features_idx]\n",
        "\n",
        "\n",
        "\n",
        "f1, auc, missing_values, class_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXD50S4mVkxH",
        "outputId": "23c35383-e26c-4ba8-a0f2-7706d358db6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ تم حفظ التوقعات بنجاح في: /content/drive/My Drive/Colab Notebooks/test_predictions_xgboost.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ✅ تحميل بيانات الاختبار (Test Set)\n",
        "test_file = \"/content/drive/My Drive/Colab Notebooks/test_features.csv\"\n",
        "df_test = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# ✅ الاحتفاظ بـ ID الأصلي\n",
        "if 'ID' in df_test.columns:\n",
        "    test_ids = df_test['ID']\n",
        "else:\n",
        "    raise ValueError(\"❌ ملف الاختبار لا يحتوي على عمود 'ID'!\")\n",
        "\n",
        "# ✅ تحميل أفضل موديل XGBoost\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# ✅ التأكد من عدم وجود Clade لأنه مش موجود في بيانات الاختبار\n",
        "if 'Clade' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام بنفس الطريقة المستخدمة أثناء التدريب\n",
        "for col in df_test.select_dtypes(include=['object']).columns:\n",
        "    df_test[col] = LabelEncoder().fit_transform(df_test[col].astype(str))\n",
        "\n",
        "# ✅ تنفيذ التوقعات باستخدام الموديل\n",
        "y_pred = best_model.predict(df_test)\n",
        "\n",
        "# ✅ تحويل التوقعات إلى DataFrame مع الـ ID\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Predicted_Clade\": y_pred\n",
        "})\n",
        "\n",
        "# ✅ حفظ التوقعات في ملف CSV\n",
        "output_file = \"/content/drive/My Drive/Colab Notebooks/test_predictions_xgboost.csv\"\n",
        "df_predictions.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✅ تم حفظ التوقعات بنجاح في: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ufEp6vWl1c",
        "outputId": "da2d7533-84ba-49cb-93a5-49d28ed4058a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 التجربة رقم 1\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068688 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.941221\n",
            "[LightGBM] [Info] Start training from score -1.948413\n",
            "[LightGBM] [Info] Start training from score -1.946911\n",
            "[LightGBM] [Info] Start training from score -1.934970\n",
            "[LightGBM] [Info] Start training from score -1.958793\n",
            "[LightGBM] [Info] Start training from score -1.943513\n",
            "[LightGBM] [Info] Start training from score -1.947712\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "📌 التجربة 1 - F1 Score: 0.8544, AUC-ROC: 0.9812\n",
            "🔹 التجربة رقم 2\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116174 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.958995\n",
            "[LightGBM] [Info] Start training from score -1.945710\n",
            "[LightGBM] [Info] Start training from score -1.932994\n",
            "[LightGBM] [Info] Start training from score -1.949617\n",
            "[LightGBM] [Info] Start training from score -1.944511\n",
            "[LightGBM] [Info] Start training from score -1.946310\n",
            "[LightGBM] [Info] Start training from score -1.943413\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "📌 التجربة 2 - F1 Score: 0.8561, AUC-ROC: 0.9814\n",
            "🔹 التجربة رقم 3\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116225 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.949918\n",
            "[LightGBM] [Info] Start training from score -1.940127\n",
            "[LightGBM] [Info] Start training from score -1.948714\n",
            "[LightGBM] [Info] Start training from score -1.939431\n",
            "[LightGBM] [Info] Start training from score -1.946911\n",
            "[LightGBM] [Info] Start training from score -1.955859\n",
            "[LightGBM] [Info] Start training from score -1.940525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "📌 التجربة 3 - F1 Score: 0.8568, AUC-ROC: 0.9806\n",
            "🔹 التجربة رقم 4\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.930529\n",
            "[LightGBM] [Info] Start training from score -1.948915\n",
            "[LightGBM] [Info] Start training from score -1.957780\n",
            "[LightGBM] [Info] Start training from score -1.946310\n",
            "[LightGBM] [Info] Start training from score -1.945011\n",
            "[LightGBM] [Info] Start training from score -1.938140\n",
            "[LightGBM] [Info] Start training from score -1.954951\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "📌 التجربة 4 - F1 Score: 0.8571, AUC-ROC: 0.9818\n",
            "✅ أفضل موديل كان في التجربة 4\n",
            "✅ F1 Score: 0.8571, AUC-ROC: 0.9818\n",
            "✅ تم حفظ الموديل في: /content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# ✅ تحميل بيانات التدريب الكاملة\n",
        "train_file = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "df_train = pd.read_csv(train_file, low_memory=False)\n",
        "\n",
        "# ✅ التأكد من وجود Clade\n",
        "if 'Clade' not in df_train.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في البيانات!\")\n",
        "\n",
        "# ✅ تحويل القيم النصية إلى أرقام باستخدام Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "df_train['Clade'] = encoder.fit_transform(df_train['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام\n",
        "for col in df_train.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # نتجنب تحويل العمود المستهدف مرتين\n",
        "        df_train[col] = LabelEncoder().fit_transform(df_train[col].astype(str))\n",
        "\n",
        "# ✅ المتغيرات لتخزين أفضل القيم\n",
        "best_model = None\n",
        "best_f1 = 0\n",
        "best_auc = 0\n",
        "best_iteration = None\n",
        "\n",
        "# ✅ تكرار العملية 4 مرات\n",
        "for i in range(1, 5):\n",
        "    print(f\"🔹 التجربة رقم {i}\")\n",
        "\n",
        "    # 🔹 اختيار 87,500 صف عشوائيًا\n",
        "    df_sample = df_train.sample(n=87500, random_state=i)\n",
        "\n",
        "    # 🔹 تقسيم البيانات 80% تدريب و 20% تحقق\n",
        "    X = df_sample.drop(columns=['Clade'])  # الميزات (features)\n",
        "    y = df_sample['Clade']  # التصنيفات (labels)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
        "\n",
        "    # ✅ تدريب الموديل باستخدام LightGBM\n",
        "    model = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # ✅ التنبؤ على بيانات التحقق\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)  # ✅ الآن نأخذ كل الاحتمالات لكل الفئات\n",
        "\n",
        "    # ✅ حساب F1 Score و AUC-ROC\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # ✅ تمرير كل الاحتمالات لكل الفئات\n",
        "\n",
        "    print(f\"📌 التجربة {i} - F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # ✅ حفظ أفضل موديل\n",
        "    if auc > best_auc:\n",
        "        best_model = model\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_iteration = i\n",
        "\n",
        "# ✅ حفظ أفضل موديل\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\"\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"✅ أفضل موديل كان في التجربة {best_iteration}\")\n",
        "print(f\"✅ F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc:.4f}\")\n",
        "print(f\"✅ تم حفظ الموديل في: {best_model_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9xyx9XhHRkm",
        "outputId": "bd588df1-4197-42a6-953f-179713d30877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 نتائج التحقق على بيانات الـ 210,000 صف:\n",
            "✅ F1 Score: 0.7735\n",
            "✅ AUC-ROC: 0.9622\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "\n",
        "# ✅ تحميل بيانات التحقق (Validation Set)\n",
        "val_file = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "df_val = pd.read_csv(val_file, low_memory=False)\n",
        "\n",
        "# ✅ تحميل أفضل موديل LightGBM\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# ✅ التأكد من وجود Clade في البيانات\n",
        "if 'Clade' not in df_val.columns:\n",
        "    raise ValueError(\"❌ العمود 'Clade' غير موجود في بيانات التحقق!\")\n",
        "\n",
        "# ✅ تحويل القيم النصية إلى أرقام باستخدام نفس LabelEncoder المستخدم في التدريب\n",
        "encoder = LabelEncoder()\n",
        "df_val['Clade'] = encoder.fit_transform(df_val['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام بنفس الطريقة المستخدمة أثناء التدريب\n",
        "for col in df_val.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # ✅ استثناء العمود المستهدف\n",
        "        df_val[col] = LabelEncoder().fit_transform(df_val[col].astype(str))\n",
        "\n",
        "# ✅ تقسيم البيانات إلى الميزات (X) والتصنيفات (y)\n",
        "X_val = df_val.drop(columns=['Clade'])\n",
        "y_val = df_val['Clade']\n",
        "\n",
        "# ✅ التنبؤ باستخدام أفضل موديل LightGBM\n",
        "y_pred = best_model.predict(X_val)\n",
        "y_pred_proba = best_model.predict_proba(X_val)  # ✅ الآن نأخذ كل الاحتمالات لكل الفئات\n",
        "\n",
        "# ✅ حساب F1 Score و AUC-ROC\n",
        "f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # ✅ تمرير كل الاحتمالات لكل الفئات\n",
        "\n",
        "# ✅ طباعة النتائج\n",
        "print(\"📌 نتائج التحقق على بيانات الـ 210,000 صف:\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(f\"✅ AUC-ROC: {auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOZbq5WpaYre",
        "outputId": "9d96a3a2-b84c-4cf0-999e-7dd938e45dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ تم حفظ التوقعات بنجاح في: /content/drive/My Drive/Colab Notebooks/test_predictions_lgbm.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "\n",
        "# ✅ تحميل بيانات الاختبار (Test Set)\n",
        "test_file = \"/content/drive/My Drive/Colab Notebooks/test_features.csv\"\n",
        "df_test = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# ✅ الاحتفاظ بـ ID الأصلي\n",
        "if 'ID' in df_test.columns:\n",
        "    test_ids = df_test['ID']\n",
        "else:\n",
        "    raise ValueError(\"❌ ملف الاختبار لا يحتوي على عمود 'ID'!\")\n",
        "\n",
        "# ✅ تحميل أفضل موديل LightGBM\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# ✅ التأكد من عدم وجود Clade لأنه مش موجود في بيانات الاختبار\n",
        "if 'Clade' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['Clade'])\n",
        "\n",
        "# 🔹 تحويل كل الأعمدة النصية إلى أرقام بنفس الطريقة المستخدمة أثناء التدريب\n",
        "for col in df_test.select_dtypes(include=['object']).columns:\n",
        "    df_test[col] = LabelEncoder().fit_transform(df_test[col].astype(str))\n",
        "\n",
        "# ✅ تنفيذ التوقعات باستخدام الموديل\n",
        "y_pred = best_model.predict(df_test)\n",
        "y_pred_proba = best_model.predict_proba(df_test)  # للحصول على احتمالات الفئات\n",
        "\n",
        "# ✅ تحويل التوقعات إلى DataFrame مع الـ ID\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Predicted_Clade\": y_pred\n",
        "})\n",
        "\n",
        "# ✅ حفظ التوقعات في ملف CSV\n",
        "output_file = \"/content/drive/My Drive/Colab Notebooks/test_predictions_lgbm.csv\"\n",
        "df_predictions.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✅ تم حفظ التوقعات بنجاح في: {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}