{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZyk1D9pNOZL",
        "outputId": "23b58fe8-35b6-4df8-f0c9-23e137eff502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2it66ZCWhJgt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/train.csv\"\n",
        "df = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ Clade\n",
        "if 'Clade' not in df.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!\")\n",
        "\n",
        "# âœ… ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚\n",
        "train_list = []\n",
        "val_list = []\n",
        "\n",
        "# âœ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Clade Ø¹Ù„Ù‰ Ø­Ø¯Ø©\n",
        "for clade, group in df.groupby('Clade'):\n",
        "    # ğŸ”¹ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ø¯Ø¯ ÙƒØ§ÙÙ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ†Ø§Øª\n",
        "    if len(group) < 50000:\n",
        "        raise ValueError(f\"âš ï¸ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Clade {clade} Ø£Ù‚Ù„ Ù…Ù† 50,000!\")\n",
        "\n",
        "    # ğŸ”¹ Ø£Ø®Ø° 50,000 Ø¹ÙŠÙ†Ø© Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "    train_clade = group.sample(n=50000, random_state=42)\n",
        "\n",
        "    # ğŸ”¹ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ°Ù‡Ø¨ Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ­Ù‚Ù‚ (Validation)\n",
        "    val_clade = group.drop(train_clade.index)\n",
        "\n",
        "    # âœ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…\n",
        "    train_list.append(train_clade)\n",
        "    val_list.append(val_clade)\n",
        "\n",
        "# âœ… ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø³Ù…Ø©\n",
        "df_train = pd.concat(train_list).reset_index(drop=True)\n",
        "df_val = pd.concat(val_list).reset_index(drop=True)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
        "if len(df_train) != 350000 or len(df_val) != 210000:\n",
        "    raise ValueError(\"âŒ Ø­Ø¬Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£Ùˆ Ø§Ù„ØªØ­Ù‚Ù‚ ØºÙŠØ± ØµØ­ÙŠØ­!\")\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\n",
        "train_output = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "val_output = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "\n",
        "df_train.to_csv(train_output, index=False)\n",
        "df_val.to_csv(val_output, index=False)\n",
        "\n",
        "print(f\"âœ… ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­:\")\n",
        "print(f\"ğŸ”¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train_output} ({len(df_train)} ØµÙ)\")\n",
        "print(f\"ğŸ”¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚: {val_output} ({len(df_val)} ØµÙ)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXlHVYjuji8K",
        "outputId": "e0b73a42-d87b-4e58-d612-fffe1fe7be3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 1\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 1 - F1 Score: 0.8336, AUC-ROC: 0.9747\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 2\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 2 - F1 Score: 0.8382, AUC-ROC: 0.9761\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 3\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 3 - F1 Score: 0.8341, AUC-ROC: 0.9751\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 4\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 4 - F1 Score: 0.8360, AUC-ROC: 0.9760\n",
            "âœ… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 2\n",
            "âœ… F1 Score: 0.8382, AUC-ROC: 0.9761\n",
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ: /content/drive/My Drive/Colab Notebooks/best_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„Ø©\n",
        "train_file = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "df_train = pd.read_csv(train_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Clade\n",
        "if 'Clade' not in df_train.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!\")\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "df_train['Clade'] = encoder.fit_transform(df_train['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…\n",
        "for col in df_train.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # Ù†ØªØ¬Ù†Ø¨ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ù…Ø±ØªÙŠÙ†\n",
        "        df_train[col] = LabelEncoder().fit_transform(df_train[col].astype(str))\n",
        "\n",
        "# âœ… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„ØªØ®Ø²ÙŠÙ† Ø£ÙØ¶Ù„ Ø§Ù„Ù‚ÙŠÙ…\n",
        "best_model = None\n",
        "best_f1 = 0\n",
        "best_auc = 0\n",
        "best_iteration = None\n",
        "\n",
        "# âœ… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© 4 Ù…Ø±Ø§Øª\n",
        "for i in range(1, 5):\n",
        "    print(f\"ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… {i}\")\n",
        "\n",
        "    # ğŸ”¹ Ø§Ø®ØªÙŠØ§Ø± 87,500 ØµÙ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§\n",
        "    df_sample = df_train.sample(n=87500, random_state=i)\n",
        "\n",
        "    # ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 80% ØªØ¯Ø±ÙŠØ¨ Ùˆ 20% ØªØ­Ù‚Ù‚\n",
        "    X = df_sample.drop(columns=['Clade'])  # Ø§Ù„Ù…ÙŠØ²Ø§Øª (features)\n",
        "    y = df_sample['Clade']  # Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª (labels)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
        "\n",
        "    # âœ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # âœ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)  # âœ… Ø§Ù„Ø¢Ù† Ù†Ø£Ø®Ø° ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "    # âœ… Ø­Ø³Ø§Ø¨ F1 Score Ùˆ AUC-ROC\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # âœ… ØªÙ…Ø±ÙŠØ± ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "    print(f\"ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© {i} - F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # âœ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "    if auc > best_auc:\n",
        "        best_model = model\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_iteration = i\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model.pkl\"\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"âœ… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© {best_iteration}\")\n",
        "print(f\"âœ… F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc:.4f}\")\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ: {best_model_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd8CsQ9Zo6v7",
        "outputId": "2c88c492-8dea-4577-bf2f-9f3e2b396845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚ Ø¹Ù„Ù‰ 210,000 ØµÙ:\n",
            "âœ… F1 Score: 0.8057\n",
            "âœ… AUC-ROC: 0.9687\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ (Validation Set)\n",
        "val_file = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "df_val = pd.read_csv(val_file, low_memory=False)\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Clade ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "if 'Clade' not in df_val.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚!\")\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ LabelEncoder Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "encoder = LabelEncoder()\n",
        "df_val['Clade'] = encoder.fit_transform(df_val['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "for col in df_val.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # âœ… Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù\n",
        "        df_val[col] = LabelEncoder().fit_transform(df_val[col].astype(str))\n",
        "\n",
        "# âœ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª (X) ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª (y)\n",
        "X_val = df_val.drop(columns=['Clade'])\n",
        "y_val = df_val['Clade']\n",
        "\n",
        "# âœ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "y_pred = best_model.predict(X_val)\n",
        "y_pred_proba = best_model.predict_proba(X_val)  # âœ… Ø§Ù„Ø¢Ù† Ù†Ø£Ø®Ø° ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "# âœ… Ø­Ø³Ø§Ø¨ F1 Score Ùˆ AUC-ROC\n",
        "f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # âœ… ØªÙ…Ø±ÙŠØ± ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "# âœ… Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "print(\"ğŸ“Œ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚ Ø¹Ù„Ù‰ 210,000 ØµÙ:\")\n",
        "print(f\"âœ… F1 Score: {f1:.4f}\")\n",
        "print(f\"âœ… AUC-ROC: {auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjRAuQjftQS3",
        "outputId": "297d3247-3948-4d66-d7b5-d2168e947d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: /content/drive/My Drive/Colab Notebooks/test_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Test Set)\n",
        "test_file = \"/content/drive/My Drive/Colab Notebooks/test_features.csv\"\n",
        "df_test = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù€ ID Ø§Ù„Ø£ØµÙ„ÙŠ\n",
        "if 'ID' in df_test.columns:\n",
        "    test_ids = df_test['ID']\n",
        "else:\n",
        "    raise ValueError(\"âŒ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'ID'!\")\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Clade Ù„Ø£Ù†Ù‡ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "if 'Clade' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "for col in df_test.select_dtypes(include=['object']).columns:\n",
        "    df_test[col] = LabelEncoder().fit_transform(df_test[col].astype(str))\n",
        "\n",
        "# âœ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "y_pred = best_model.predict(df_test)\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¥Ù„Ù‰ DataFrame Ù…Ø¹ Ø§Ù„Ù€ ID\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Predicted_Clade\": y_pred\n",
        "})\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª ÙÙŠ Ù…Ù„Ù CSV\n",
        "output_file = \"/content/drive/My Drive/Colab Notebooks/test_predictions.csv\"\n",
        "df_predictions.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSyT-_L77FsL",
        "outputId": "bb929423-962f-4ae1-857f-4e5f7752491b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:12:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 1 - F1 Score: 0.8523, AUC-ROC: 0.9810\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:14:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 2 - F1 Score: 0.8531, AUC-ROC: 0.9808\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:16:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 3 - F1 Score: 0.8512, AUC-ROC: 0.9802\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:17:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 4 - F1 Score: 0.8541, AUC-ROC: 0.9812\n",
            "âœ… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 4\n",
            "âœ… F1 Score: 0.8541, AUC-ROC: 0.9812\n",
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ: /content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\n",
            "âœ… ØªÙ… Ø­ÙØ¸ StandardScaler ÙÙŠ: /content/drive/My Drive/Colab Notebooks/best_scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pickle\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "train_file = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "df_train = pd.read_csv(train_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Clade\n",
        "if 'Clade' not in df_train.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!\")\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "df_train['Clade'] = encoder.fit_transform(df_train['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…\n",
        "for col in df_train.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':\n",
        "        df_train[col] = LabelEncoder().fit_transform(df_train[col].astype(str))\n",
        "\n",
        "# âœ… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "best_model = None\n",
        "best_f1 = 0\n",
        "best_auc = 0\n",
        "best_iteration = None\n",
        "\n",
        "# âœ… ØªØ¬Ø±Ø¨Ø© 4 Ù…Ø±Ø§Øª ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„\n",
        "for i in range(1, 5):\n",
        "    print(f\"ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… {i}\")\n",
        "\n",
        "    # ğŸ”¹ Ø§Ø®ØªÙŠØ§Ø± 87,500 ØµÙ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§\n",
        "    df_sample = df_train.sample(n=87500, random_state=i)\n",
        "\n",
        "    # ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 80% ØªØ¯Ø±ÙŠØ¨ Ùˆ 20% ØªØ­Ù‚Ù‚\n",
        "    X = df_sample.drop(columns=['Clade'])\n",
        "    y = df_sample['Clade']\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
        "\n",
        "    # âœ… ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "\n",
        "    # âœ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… XGBoost\n",
        "    model = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # âœ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)\n",
        "\n",
        "    # âœ… Ø­Ø³Ø§Ø¨ F1 Score Ùˆ AUC-ROC\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")\n",
        "\n",
        "    print(f\"ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© {i} - F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # âœ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "    if auc > best_auc:\n",
        "        best_model = model\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_iteration = i\n",
        "        best_scaler = scaler\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ùˆ StandardScaler\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\"\n",
        "scaler_file = \"/content/drive/My Drive/Colab Notebooks/best_scaler.pkl\"\n",
        "\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "with open(scaler_file, 'wb') as f:\n",
        "    pickle.dump(best_scaler, f)\n",
        "\n",
        "print(f\"âœ… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© {best_iteration}\")\n",
        "print(f\"âœ… F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc:.4f}\")\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ: {best_model_file}\")\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ StandardScaler ÙÙŠ: {scaler_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvxv99dWvzNh",
        "outputId": "39cc3127-a0c4-4e2c-f3ee-757cc6a49ffb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8492558954724528,\n",
              " 0.9802253145655241,\n",
              " ID       0\n",
              " AA       0\n",
              " AC       0\n",
              " AG       0\n",
              " AT       0\n",
              "         ..\n",
              " TTA      0\n",
              " TTC      0\n",
              " TTG      0\n",
              " TTT      0\n",
              " Clade    0\n",
              " Length: 82, dtype: int64,\n",
              " Clade\n",
              " 5    34170\n",
              " 0    31274\n",
              " 3    30483\n",
              " 1    30130\n",
              " 4    28825\n",
              " 6    28618\n",
              " 2    26500\n",
              " Name: count, dtype: int64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚\n",
        "val_file = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "df_val = pd.read_csv(val_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©\n",
        "missing_values = df_val.isnull().sum()\n",
        "\n",
        "# âœ… Ø­Ø°Ù Ø£Ùˆ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©\n",
        "df_val = df_val.dropna()\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Clade ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "if 'Clade' not in df_val.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚!\")\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ LabelEncoder Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "encoder = LabelEncoder()\n",
        "df_val['Clade'] = encoder.fit_transform(df_val['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "for col in df_val.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':\n",
        "        df_val[col] = LabelEncoder().fit_transform(df_val[col].astype(str))\n",
        "\n",
        "# âœ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª (X) ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª (y)\n",
        "X_val = df_val.drop(columns=['Clade'])\n",
        "y_val = df_val['Clade']\n",
        "\n",
        "# âœ… ØªØ­Ù„ÙŠÙ„ ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª\n",
        "class_distribution = y_val.value_counts()\n",
        "\n",
        "# âœ… Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_val_balanced, y_val_balanced = smote.fit_resample(X_val, y_val)\n",
        "\n",
        "# âœ… ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "scaler = StandardScaler()\n",
        "X_val_scaled = scaler.fit_transform(X_val_balanced)\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ XGBoost\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# âœ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ XGBoost\n",
        "y_pred = best_model.predict(X_val_scaled)\n",
        "y_pred_proba = best_model.predict_proba(X_val_scaled)\n",
        "\n",
        "# âœ… Ø­Ø³Ø§Ø¨ F1 Score Ùˆ AUC-ROC\n",
        "f1 = f1_score(y_val_balanced, y_pred, average='weighted')\n",
        "auc = roc_auc_score(y_val_balanced, y_pred_proba, multi_class=\"ovr\")\n",
        "\n",
        "# âœ… ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
        "feature_importance = best_model.feature_importances_\n",
        "top_features_idx = np.argsort(feature_importance)[-10:]\n",
        "top_features = X_val.columns[top_features_idx]\n",
        "top_importances = feature_importance[top_features_idx]\n",
        "\n",
        "\n",
        "\n",
        "f1, auc, missing_values, class_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXD50S4mVkxH",
        "outputId": "23c35383-e26c-4ba8-a0f2-7706d358db6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: /content/drive/My Drive/Colab Notebooks/test_predictions_xgboost.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Test Set)\n",
        "test_file = \"/content/drive/My Drive/Colab Notebooks/test_features.csv\"\n",
        "df_test = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù€ ID Ø§Ù„Ø£ØµÙ„ÙŠ\n",
        "if 'ID' in df_test.columns:\n",
        "    test_ids = df_test['ID']\n",
        "else:\n",
        "    raise ValueError(\"âŒ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'ID'!\")\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ XGBoost\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_xgboost.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Clade Ù„Ø£Ù†Ù‡ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "if 'Clade' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "for col in df_test.select_dtypes(include=['object']).columns:\n",
        "    df_test[col] = LabelEncoder().fit_transform(df_test[col].astype(str))\n",
        "\n",
        "# âœ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "y_pred = best_model.predict(df_test)\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¥Ù„Ù‰ DataFrame Ù…Ø¹ Ø§Ù„Ù€ ID\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Predicted_Clade\": y_pred\n",
        "})\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª ÙÙŠ Ù…Ù„Ù CSV\n",
        "output_file = \"/content/drive/My Drive/Colab Notebooks/test_predictions_xgboost.csv\"\n",
        "df_predictions.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ufEp6vWl1c",
        "outputId": "da2d7533-84ba-49cb-93a5-49d28ed4058a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 1\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068688 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.941221\n",
            "[LightGBM] [Info] Start training from score -1.948413\n",
            "[LightGBM] [Info] Start training from score -1.946911\n",
            "[LightGBM] [Info] Start training from score -1.934970\n",
            "[LightGBM] [Info] Start training from score -1.958793\n",
            "[LightGBM] [Info] Start training from score -1.943513\n",
            "[LightGBM] [Info] Start training from score -1.947712\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 1 - F1 Score: 0.8544, AUC-ROC: 0.9812\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 2\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116174 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.958995\n",
            "[LightGBM] [Info] Start training from score -1.945710\n",
            "[LightGBM] [Info] Start training from score -1.932994\n",
            "[LightGBM] [Info] Start training from score -1.949617\n",
            "[LightGBM] [Info] Start training from score -1.944511\n",
            "[LightGBM] [Info] Start training from score -1.946310\n",
            "[LightGBM] [Info] Start training from score -1.943413\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 2 - F1 Score: 0.8561, AUC-ROC: 0.9814\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 3\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116225 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.949918\n",
            "[LightGBM] [Info] Start training from score -1.940127\n",
            "[LightGBM] [Info] Start training from score -1.948714\n",
            "[LightGBM] [Info] Start training from score -1.939431\n",
            "[LightGBM] [Info] Start training from score -1.946911\n",
            "[LightGBM] [Info] Start training from score -1.955859\n",
            "[LightGBM] [Info] Start training from score -1.940525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 3 - F1 Score: 0.8568, AUC-ROC: 0.9806\n",
            "ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… 4\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20655\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 81\n",
            "[LightGBM] [Info] Start training from score -1.930529\n",
            "[LightGBM] [Info] Start training from score -1.948915\n",
            "[LightGBM] [Info] Start training from score -1.957780\n",
            "[LightGBM] [Info] Start training from score -1.946310\n",
            "[LightGBM] [Info] Start training from score -1.945011\n",
            "[LightGBM] [Info] Start training from score -1.938140\n",
            "[LightGBM] [Info] Start training from score -1.954951\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 4 - F1 Score: 0.8571, AUC-ROC: 0.9818\n",
            "âœ… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 4\n",
            "âœ… F1 Score: 0.8571, AUC-ROC: 0.9818\n",
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ: /content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„Ø©\n",
        "train_file = \"/content/drive/My Drive/Colab Notebooks/train_split.csv\"\n",
        "df_train = pd.read_csv(train_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Clade\n",
        "if 'Clade' not in df_train.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!\")\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Label Encoding\n",
        "encoder = LabelEncoder()\n",
        "df_train['Clade'] = encoder.fit_transform(df_train['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…\n",
        "for col in df_train.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # Ù†ØªØ¬Ù†Ø¨ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ù…Ø±ØªÙŠÙ†\n",
        "        df_train[col] = LabelEncoder().fit_transform(df_train[col].astype(str))\n",
        "\n",
        "# âœ… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„ØªØ®Ø²ÙŠÙ† Ø£ÙØ¶Ù„ Ø§Ù„Ù‚ÙŠÙ…\n",
        "best_model = None\n",
        "best_f1 = 0\n",
        "best_auc = 0\n",
        "best_iteration = None\n",
        "\n",
        "# âœ… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© 4 Ù…Ø±Ø§Øª\n",
        "for i in range(1, 5):\n",
        "    print(f\"ğŸ”¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø±Ù‚Ù… {i}\")\n",
        "\n",
        "    # ğŸ”¹ Ø§Ø®ØªÙŠØ§Ø± 87,500 ØµÙ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§\n",
        "    df_sample = df_train.sample(n=87500, random_state=i)\n",
        "\n",
        "    # ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 80% ØªØ¯Ø±ÙŠØ¨ Ùˆ 20% ØªØ­Ù‚Ù‚\n",
        "    X = df_sample.drop(columns=['Clade'])  # Ø§Ù„Ù…ÙŠØ²Ø§Øª (features)\n",
        "    y = df_sample['Clade']  # Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª (labels)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
        "\n",
        "    # âœ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LightGBM\n",
        "    model = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # âœ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)  # âœ… Ø§Ù„Ø¢Ù† Ù†Ø£Ø®Ø° ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "    # âœ… Ø­Ø³Ø§Ø¨ F1 Score Ùˆ AUC-ROC\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # âœ… ØªÙ…Ø±ÙŠØ± ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "    print(f\"ğŸ“Œ Ø§Ù„ØªØ¬Ø±Ø¨Ø© {i} - F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # âœ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "    if auc > best_auc:\n",
        "        best_model = model\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "        best_iteration = i\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\"\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"âœ… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø© {best_iteration}\")\n",
        "print(f\"âœ… F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc:.4f}\")\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ: {best_model_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9xyx9XhHRkm",
        "outputId": "bd588df1-4197-42a6-953f-179713d30877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù€ 210,000 ØµÙ:\n",
            "âœ… F1 Score: 0.7735\n",
            "âœ… AUC-ROC: 0.9622\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ (Validation Set)\n",
        "val_file = \"/content/drive/My Drive/Colab Notebooks/val_split.csv\"\n",
        "df_val = pd.read_csv(val_file, low_memory=False)\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ LightGBM\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Clade ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "if 'Clade' not in df_val.columns:\n",
        "    raise ValueError(\"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ 'Clade' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚!\")\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ LabelEncoder Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "encoder = LabelEncoder()\n",
        "df_val['Clade'] = encoder.fit_transform(df_val['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "for col in df_val.select_dtypes(include=['object']).columns:\n",
        "    if col != 'Clade':  # âœ… Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù\n",
        "        df_val[col] = LabelEncoder().fit_transform(df_val[col].astype(str))\n",
        "\n",
        "# âœ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª (X) ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª (y)\n",
        "X_val = df_val.drop(columns=['Clade'])\n",
        "y_val = df_val['Clade']\n",
        "\n",
        "# âœ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ LightGBM\n",
        "y_pred = best_model.predict(X_val)\n",
        "y_pred_proba = best_model.predict_proba(X_val)  # âœ… Ø§Ù„Ø¢Ù† Ù†Ø£Ø®Ø° ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "# âœ… Ø­Ø³Ø§Ø¨ F1 Score Ùˆ AUC-ROC\n",
        "f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "auc = roc_auc_score(y_val, y_pred_proba, multi_class=\"ovr\")  # âœ… ØªÙ…Ø±ÙŠØ± ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "# âœ… Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "print(\"ğŸ“Œ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù€ 210,000 ØµÙ:\")\n",
        "print(f\"âœ… F1 Score: {f1:.4f}\")\n",
        "print(f\"âœ… AUC-ROC: {auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOZbq5WpaYre",
        "outputId": "9d96a3a2-b84c-4cf0-999e-7dd938e45dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: /content/drive/My Drive/Colab Notebooks/test_predictions_lgbm.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Test Set)\n",
        "test_file = \"/content/drive/My Drive/Colab Notebooks/test_features.csv\"\n",
        "df_test = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# âœ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù€ ID Ø§Ù„Ø£ØµÙ„ÙŠ\n",
        "if 'ID' in df_test.columns:\n",
        "    test_ids = df_test['ID']\n",
        "else:\n",
        "    raise ValueError(\"âŒ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'ID'!\")\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ LightGBM\n",
        "best_model_file = \"/content/drive/My Drive/Colab Notebooks/best_model_lightgbm1.pkl\"\n",
        "with open(best_model_file, 'rb') as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# âœ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Clade Ù„Ø£Ù†Ù‡ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "if 'Clade' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['Clade'])\n",
        "\n",
        "# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "for col in df_test.select_dtypes(include=['object']).columns:\n",
        "    df_test[col] = LabelEncoder().fit_transform(df_test[col].astype(str))\n",
        "\n",
        "# âœ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "y_pred = best_model.predict(df_test)\n",
        "y_pred_proba = best_model.predict_proba(df_test)  # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„ÙØ¦Ø§Øª\n",
        "\n",
        "# âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¥Ù„Ù‰ DataFrame Ù…Ø¹ Ø§Ù„Ù€ ID\n",
        "df_predictions = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Predicted_Clade\": y_pred\n",
        "})\n",
        "\n",
        "# âœ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª ÙÙŠ Ù…Ù„Ù CSV\n",
        "output_file = \"/content/drive/My Drive/Colab Notebooks/test_predictions_lgbm.csv\"\n",
        "df_predictions.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}